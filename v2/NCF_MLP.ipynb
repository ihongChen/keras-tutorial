{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import keras \n",
    "from Dataset import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = Dataset('./data/ml-1m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train, testRatings, testNegatives = dataset.trainMatrix, dataset.testRatings, dataset.testNegatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6040, 3706)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape # train is sparse matrix 6040x3706"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6040"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(testRatings) # 6040 list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 25],\n",
       " [1, 133],\n",
       " [2, 207],\n",
       " [3, 208],\n",
       " [4, 222],\n",
       " [5, 396],\n",
       " [6, 74],\n",
       " [7, 91],\n",
       " [8, 514],\n",
       " [9, 659]]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testRatings[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6040"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(testNegatives) # 6040 list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(testNegatives[:10][2]) # 99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_users,num_items = train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Input, Model\n",
    "from keras.layers import Embedding, Flatten, merge, Dense,regularizers\n",
    "from keras.layers import concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'embedding_2/Gather:0' shape=(?, 1, 10) dtype=float32>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_input = Input(shape = (1,), name = 'user_input',dtype = 'int32')\n",
    "MLP_Embedding_User = Embedding(input_dim = num_users,output_dim = int(layers[0]/2))\n",
    "MLP_Embedding_User(user_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = get_model(num_users,num_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_model(num_users, num_items, layers = [20,10], reg_layers=[0,0]):\n",
    "    assert len(layers) == len(reg_layers)\n",
    "    num_layer = len(layers) #Number of layers in the MLP\n",
    "    # Input variables\n",
    "    user_input = Input(shape=(1,), dtype='int32', name = 'user_input')\n",
    "    item_input = Input(shape=(1,), dtype='int32', name = 'item_input')\n",
    "\n",
    "    MLP_Embedding_User = Embedding(input_dim = num_users,\n",
    "                                   output_dim = int(layers[0]/2), \n",
    "                                   name = 'user_embedding',\n",
    "                                   embeddings_initializer = 'uniform',\n",
    "                                   embeddings_regularizer = regularizers.l2(0),\n",
    "                                   input_length=1) # model size : (None,1,layers[0]/2)\n",
    "    \n",
    "    MLP_Embedding_Item = Embedding(input_dim = num_items,\n",
    "                                   output_dim = int(layers[0]/2),\n",
    "                                   name = 'item_embedding',\n",
    "                                   embeddings_initializer = 'uniform',\n",
    "                                   embeddings_regularizer = regularizers.l2(0),\n",
    "                                   input_length=1)   \n",
    "    \n",
    "    # Crucial to flatten an embedding vector!\n",
    "    user_latent = Flatten()(MLP_Embedding_User(user_input))\n",
    "    item_latent = Flatten()(MLP_Embedding_Item(item_input))\n",
    "    \n",
    "    # The 0-th layer is the concatenation of embedding layers\n",
    "    vector = concatenate([user_latent, item_latent])\n",
    "    \n",
    "    # MLP layers\n",
    "    for idx in range(1, num_layer):\n",
    "        layer = Dense(layers[idx],\n",
    "                      kernel_regularizer = regularizers.l2(reg_layers[idx]), activation='relu', name = 'layer%d' %idx)\n",
    "        vector = layer(vector)\n",
    "        \n",
    "    # Final prediction layer\n",
    "    prediction = Dense(1, activation='sigmoid', kernel_initializer='lecun_uniform', name = 'prediction')(vector)\n",
    "    \n",
    "    model = Model(inputs=[user_input, item_input], \n",
    "                  outputs=prediction)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "u_input = Input(shape = (1,), dtype='int32', name = 'user_input')\n",
    "i_input = Input(shape = (1,), dtype = 'int32', name = 'item_input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "layers = [20,10]\n",
    "reg_layers = [0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(1)])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MLP_Embedding_User = Embedding(input_dim = num_users, \n",
    "                               output_dim = layers[0]/2,\n",
    "                               name = 'user_embedding',\n",
    "                               embeddings_initializer = 'uniform',                               \n",
    "                               W_regularizer = l2(reg_layers[0]),\n",
    "                               input_length=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MLP_Embedding_Item = Embedding(input_dim = num_items,\n",
    "                               output_dim = layers[0]/2, \n",
    "                               name = 'item_embedding',\n",
    "                               embeddings_initializer = 'uniform',\n",
    "                               embeddings_regularizer = regularizers.l2(0),\n",
    "                               input_length=1) # model size : (None,1,layers[0]/2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activity_regularizer': None,\n",
       " 'batch_input_shape': (None, 1),\n",
       " 'dtype': 'float32',\n",
       " 'embeddings_constraint': None,\n",
       " 'embeddings_initializer': {'class_name': 'RandomUniform',\n",
       "  'config': {'maxval': 0.05, 'minval': -0.05, 'seed': None}},\n",
       " 'embeddings_regularizer': {'class_name': 'L1L2',\n",
       "  'config': {'l1': 0.0, 'l2': 0.0}},\n",
       " 'input_dim': 6040,\n",
       " 'input_length': 1,\n",
       " 'mask_zero': False,\n",
       " 'name': 'user_embedding',\n",
       " 'output_dim': 10.0,\n",
       " 'trainable': True}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MLP_Embedding_User.get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activity_regularizer': None,\n",
       " 'batch_input_shape': (None, 1),\n",
       " 'dtype': 'float32',\n",
       " 'embeddings_constraint': None,\n",
       " 'embeddings_initializer': {'class_name': 'RandomUniform',\n",
       "  'config': {'maxval': 0.05, 'minval': -0.05, 'seed': None}},\n",
       " 'embeddings_regularizer': {'class_name': 'L1L2',\n",
       "  'config': {'l1': 0.0, 'l2': 0.0}},\n",
       " 'input_dim': 3706,\n",
       " 'input_length': 1,\n",
       " 'mask_zero': False,\n",
       " 'name': 'item_embedding',\n",
       " 'output_dim': 10.0,\n",
       " 'trainable': True}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MLP_Embedding_Item.get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'evaluate' from 'd:\\\\ihong\\\\py_repo\\\\DL\\\\keras_tutorial\\\\v2\\\\evaluate.py'>"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(evaluate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import evaluate\n",
    "import numpy as np \n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init: HR = 0.0934, NDCG = 0.0416 [4.2]\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.001\n",
    "model.compile(optimizer=keras.optimizers.Adagrad(lr=learning_rate), loss='binary_crossentropy')\n",
    "\n",
    "# evaluate_model(model, testRatings, testNegatives, K = 10, num_thread = 1)\n",
    "t1 = time()\n",
    "(hits, ndcgs) = evaluate_model(model, testRatings, testNegatives, K=10, num_thread = 1)\n",
    "hr, ndcg = np.array(hits).mean(), np.array(ndcgs).mean()\n",
    "print('Init: HR = %.4f, NDCG = %.4f [%.1f]' %(hr, ndcg, time()-t1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_train_instances(train, num_negatives):\n",
    "    user_input, item_input, labels = [],[],[]\n",
    "    num_users = train.shape[0]\n",
    "    for (u, i) in train.keys():\n",
    "        # positive instance\n",
    "        user_input.append(u)\n",
    "        item_input.append(i)\n",
    "        labels.append(1)\n",
    "        # negative instances\n",
    "        for t in range(num_negatives):\n",
    "            j = np.random.randint(num_items)\n",
    "            while (u and j) in train.keys():\n",
    "                j = np.random.randint(num_items)\n",
    "            user_input.append(u)\n",
    "            item_input.append(j)\n",
    "            labels.append(0)\n",
    "    return user_input, item_input, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0 [32.8 s]: HR = 0.4536, NDCG = 0.2533, loss = 0.3905 [4.2 s]\n",
      "Iteration 1 [32.0 s]: HR = 0.4538, NDCG = 0.2536, loss = 0.3904 [4.1 s]\n",
      "Iteration 2 [31.5 s]: HR = 0.4548, NDCG = 0.2540, loss = 0.3904 [4.2 s]\n",
      "Iteration 3 [32.6 s]: HR = 0.4540, NDCG = 0.2534, loss = 0.3899 [4.2 s]\n",
      "Iteration 4 [34.3 s]: HR = 0.4545, NDCG = 0.2534, loss = 0.3900 [4.2 s]\n",
      "Iteration 5 [32.6 s]: HR = 0.4541, NDCG = 0.2537, loss = 0.3899 [4.2 s]\n",
      "Iteration 6 [32.1 s]: HR = 0.4535, NDCG = 0.2535, loss = 0.3898 [4.2 s]\n",
      "Iteration 7 [32.3 s]: HR = 0.4533, NDCG = 0.2534, loss = 0.3897 [4.2 s]\n",
      "Iteration 8 [31.9 s]: HR = 0.4533, NDCG = 0.2530, loss = 0.3896 [4.2 s]\n",
      "Iteration 9 [32.2 s]: HR = 0.4535, NDCG = 0.2534, loss = 0.3894 [4.1 s]\n",
      "Iteration 10 [32.8 s]: HR = 0.4530, NDCG = 0.2536, loss = 0.3894 [4.2 s]\n",
      "Iteration 11 [31.6 s]: HR = 0.4540, NDCG = 0.2539, loss = 0.3894 [4.2 s]\n",
      "Iteration 12 [32.1 s]: HR = 0.4533, NDCG = 0.2536, loss = 0.3892 [4.1 s]\n",
      "Iteration 13 [31.8 s]: HR = 0.4536, NDCG = 0.2538, loss = 0.3893 [4.2 s]\n",
      "Iteration 14 [32.2 s]: HR = 0.4536, NDCG = 0.2542, loss = 0.3892 [4.3 s]\n",
      "Iteration 15 [31.8 s]: HR = 0.4525, NDCG = 0.2536, loss = 0.3890 [4.2 s]\n",
      "Iteration 16 [31.9 s]: HR = 0.4530, NDCG = 0.2535, loss = 0.3891 [4.2 s]\n",
      "Iteration 17 [31.8 s]: HR = 0.4523, NDCG = 0.2533, loss = 0.3890 [4.2 s]\n",
      "Iteration 18 [31.8 s]: HR = 0.4525, NDCG = 0.2534, loss = 0.3888 [4.2 s]\n",
      "Iteration 19 [31.9 s]: HR = 0.4526, NDCG = 0.2534, loss = 0.3889 [4.3 s]\n",
      "End. Best Iteration 2:  HR = 0.4548, NDCG = 0.2540. \n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "num_negatives = 4 # \n",
    "epochs = 20 # \n",
    "batch_size = 256\n",
    "layers = [64,32,16,8]\n",
    "verbose = 1 \n",
    "topK = 10\n",
    "evaluation_threads = 1\n",
    "# out = 1\n",
    "#####\n",
    "\n",
    "best_hr, best_ndcg, best_iter = hr, ndcg, -1\n",
    "for epoch in range(epochs):\n",
    "    t1 = time()\n",
    "    # Generate training instances\n",
    "    user_input, item_input, labels = get_train_instances(train, num_negatives)\n",
    "\n",
    "    # Training        \n",
    "    hbist = model.fit([np.array(user_input), np.array(item_input)], #input\n",
    "                     np.array(labels), # labels \n",
    "                     batch_size=batch_size, epochs=1, verbose=0, shuffle=True)\n",
    "    t2 = time()\n",
    "\n",
    "    # Evaluation\n",
    "    if epoch %verbose == 0:\n",
    "        (hits, ndcgs) = evaluate_model(model, testRatings, testNegatives, topK, evaluation_threads)\n",
    "        hr, ndcg, loss = np.array(hits).mean(), np.array(ndcgs).mean(), hist.history['loss'][0]\n",
    "        print('Iteration %d [%.1f s]: HR = %.4f, NDCG = %.4f, loss = %.4f [%.1f s]' \n",
    "              % (epoch,  t2-t1, hr, ndcg, loss, time()-t2))\n",
    "        if hr > best_hr:\n",
    "            best_hr, best_ndcg, best_iter = hr, ndcg, epoch\n",
    "#             if out > 0:\n",
    "#                 model.save_weights(model_out_file, overwrite=True)\n",
    "\n",
    "print(\"End. Best Iteration %d:  HR = %.4f, NDCG = %.4f. \" %(best_iter, best_hr, best_ndcg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import heapq # for retrieval topK\n",
    "import multiprocessing\n",
    "import numpy as np\n",
    "from time import time\n",
    "\n",
    "#from numba import jit, autojit\n",
    "\n",
    "# Global variables that are shared across processes\n",
    "_model = None\n",
    "_testRatings = None\n",
    "_testNegatives = None\n",
    "_K = None\n",
    "\n",
    "def evaluate_model(model, testRatings, testNegatives, K, num_thread):\n",
    "    \"\"\"\n",
    "    Evaluate the performance (Hit_Ratio, NDCG) of top-K recommendation\n",
    "    Return: score of each test rating.\n",
    "    \"\"\"\n",
    "    global _model\n",
    "    global _testRatings\n",
    "    global _testNegatives\n",
    "    global _K\n",
    "    _model = model\n",
    "    _testRatings = testRatings\n",
    "    _testNegatives = testNegatives\n",
    "    _K = K\n",
    "        \n",
    "    hits, ndcgs = [],[]\n",
    "    if(num_thread > 1): # Multi-thread\n",
    "        pool = multiprocessing.Pool(processes=num_thread)\n",
    "        res = pool.map(eval_one_rating, range(len(_testRatings)))\n",
    "        pool.close()\n",
    "        pool.join()\n",
    "        hits = [r[0] for r in res]\n",
    "        ndcgs = [r[1] for r in res]\n",
    "        return (hits, ndcgs)\n",
    "    # Single thread\n",
    "    for idx in range(len(_testRatings)):\n",
    "        (hr,ndcg) = eval_one_rating(idx)\n",
    "        hits.append(hr)\n",
    "        ndcgs.append(ndcg)      \n",
    "    return (hits, ndcgs)\n",
    "\n",
    "def eval_one_rating(idx):\n",
    "    rating = _testRatings[idx]\n",
    "    items = _testNegatives[idx]\n",
    "    u = rating[0]\n",
    "    gtItem = rating[1]\n",
    "    items.append(gtItem)\n",
    "    # Get prediction scores\n",
    "    map_item_score = {}\n",
    "    users = np.full(len(items), u, dtype = 'int32')\n",
    "    predictions = _model.predict([users, np.array(items)], \n",
    "                                 batch_size=100, verbose=0)\n",
    "    for i in range(len(items)):\n",
    "        item = items[i]\n",
    "        map_item_score[item] = predictions[i]\n",
    "    items.pop()\n",
    "    \n",
    "    # Evaluate top rank list\n",
    "    ranklist = heapq.nlargest(_K, map_item_score, key=map_item_score.get)\n",
    "    hr = getHitRatio(ranklist, gtItem)\n",
    "    ndcg = getNDCG(ranklist, gtItem)\n",
    "    return (hr, ndcg)\n",
    "\n",
    "def getHitRatio(ranklist, gtItem):\n",
    "    for item in ranklist:\n",
    "        if item == gtItem:\n",
    "            return 1\n",
    "    return 0\n",
    "\n",
    "def getNDCG(ranklist, gtItem):\n",
    "    for i in range(len(ranklist)):\n",
    "        item = ranklist[i]\n",
    "        if item == gtItem:\n",
    "            return math.log(2) / math.log(i+2)\n",
    "    return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([133, 133, 133, 133, 133, 133, 133, 133, 133, 133, 133, 133, 133,\n",
       "       133, 133, 133, 133, 133, 133, 133, 133, 133, 133, 133, 133, 133,\n",
       "       133, 133, 133, 133, 133, 133, 133, 133, 133, 133, 133, 133, 133,\n",
       "       133, 133, 133, 133, 133, 133, 133, 133, 133, 133, 133, 133, 133,\n",
       "       133, 133, 133, 133, 133, 133, 133, 133, 133, 133, 133, 133, 133,\n",
       "       133, 133, 133, 133, 133, 133, 133, 133, 133, 133, 133, 133, 133,\n",
       "       133, 133, 133, 133, 133, 133, 133, 133, 133, 133, 133, 133, 133,\n",
       "       133, 133, 133, 133, 133, 133, 133, 133])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(99,)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(items).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1072, 3154, 3368, 3644,  549, 1810,  937, 1514, 1713, 2186,  660,\n",
       "       2303, 2416,  670, 1176,  788,  889, 3120, 2344, 2525, 3301, 2055,\n",
       "       1436, 2630,   11, 2773, 2176, 1847,  740, 2332, 3561,  263, 3658,\n",
       "       3282, 1980, 2093, 3287, 3190, 3475,  569, 2315, 1442,  592,  546,\n",
       "       3133, 1852, 2648,  934,  337,  483, 1017, 3452,  467, 1183, 1765,\n",
       "        601, 2413, 2602, 2801, 2976,  918,  753, 3540, 3341, 2973, 1580,\n",
       "       2118, 3511,  526, 1719,  525, 1520,  486,  557, 1353,  500, 2902,\n",
       "       1687, 1295, 2997, 2415,  797, 2518,  926, 3537, 1746, 1676, 1875,\n",
       "       3029, 1535,  341, 3525, 1429, 2225, 1628, 2061,  469, 3056, 2553])"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(99, 1)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating = testRatings[1];\n",
    "items = testNegatives[1]; # len = 99\n",
    "u = rating[1] # 0\n",
    "users = np.full(len(items), u, dtype = 'int32')\n",
    "predictions = model.predict([users, np.array(items)],batch_size = 100, verbose=0) # users -> (99,) , items -> (99,)\n",
    "predictions.shape # (99,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2553"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map_item_score = {}\n",
    "for i in range(len(items)):\n",
    "    item = items[i]\n",
    "    map_item_score[item] = predictions[i]\n",
    "items.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{11: array([ 0.14165312], dtype=float32),\n",
       " 263: array([ 0.4957276], dtype=float32),\n",
       " 337: array([ 0.30453429], dtype=float32),\n",
       " 341: array([ 0.05421362], dtype=float32),\n",
       " 467: array([ 0.29047358], dtype=float32),\n",
       " 469: array([ 0.24630435], dtype=float32),\n",
       " 483: array([ 0.24569876], dtype=float32),\n",
       " 486: array([ 0.53998804], dtype=float32),\n",
       " 500: array([ 0.34748152], dtype=float32),\n",
       " 525: array([ 0.40124953], dtype=float32),\n",
       " 526: array([ 0.22707066], dtype=float32),\n",
       " 546: array([ 0.48369297], dtype=float32),\n",
       " 549: array([ 0.0347945], dtype=float32),\n",
       " 557: array([ 0.27600738], dtype=float32),\n",
       " 569: array([ 0.17987074], dtype=float32),\n",
       " 592: array([ 0.21300307], dtype=float32),\n",
       " 601: array([ 0.24544401], dtype=float32),\n",
       " 660: array([ 0.13015649], dtype=float32),\n",
       " 670: array([ 0.16243596], dtype=float32),\n",
       " 740: array([ 0.46578985], dtype=float32),\n",
       " 753: array([ 0.33468956], dtype=float32),\n",
       " 788: array([ 0.56217146], dtype=float32),\n",
       " 797: array([ 0.511473], dtype=float32),\n",
       " 889: array([ 0.18964061], dtype=float32),\n",
       " 918: array([ 0.27735069], dtype=float32),\n",
       " 926: array([ 0.22114061], dtype=float32),\n",
       " 934: array([ 0.22283772], dtype=float32),\n",
       " 937: array([ 0.29092172], dtype=float32),\n",
       " 1017: array([ 0.19978832], dtype=float32),\n",
       " 1072: array([ 0.26851368], dtype=float32),\n",
       " 1176: array([ 0.31731468], dtype=float32),\n",
       " 1183: array([ 0.08813722], dtype=float32),\n",
       " 1295: array([ 0.24397716], dtype=float32),\n",
       " 1353: array([ 0.11126769], dtype=float32),\n",
       " 1429: array([ 0.13579072], dtype=float32),\n",
       " 1436: array([ 0.12354601], dtype=float32),\n",
       " 1442: array([ 0.16191606], dtype=float32),\n",
       " 1514: array([ 0.01911222], dtype=float32),\n",
       " 1520: array([ 0.19669619], dtype=float32),\n",
       " 1535: array([ 0.39875239], dtype=float32),\n",
       " 1580: array([ 0.13695881], dtype=float32),\n",
       " 1628: array([ 0.21171747], dtype=float32),\n",
       " 1676: array([ 0.05252684], dtype=float32),\n",
       " 1687: array([ 0.26220191], dtype=float32),\n",
       " 1713: array([ 0.0348569], dtype=float32),\n",
       " 1719: array([ 0.07664468], dtype=float32),\n",
       " 1746: array([ 0.03775368], dtype=float32),\n",
       " 1765: array([ 0.06670708], dtype=float32),\n",
       " 1810: array([ 0.1903175], dtype=float32),\n",
       " 1847: array([ 0.24408935], dtype=float32),\n",
       " 1852: array([ 0.17732616], dtype=float32),\n",
       " 1875: array([ 0.13660106], dtype=float32),\n",
       " 1980: array([ 0.03696883], dtype=float32),\n",
       " 2055: array([ 0.17148426], dtype=float32),\n",
       " 2061: array([ 0.0958684], dtype=float32),\n",
       " 2093: array([ 0.15697299], dtype=float32),\n",
       " 2118: array([ 0.06055649], dtype=float32),\n",
       " 2176: array([ 0.08349587], dtype=float32),\n",
       " 2186: array([ 0.02805619], dtype=float32),\n",
       " 2225: array([ 0.07335702], dtype=float32),\n",
       " 2303: array([ 0.04375927], dtype=float32),\n",
       " 2315: array([ 0.02642485], dtype=float32),\n",
       " 2332: array([ 0.14277378], dtype=float32),\n",
       " 2344: array([ 0.09840906], dtype=float32),\n",
       " 2413: array([ 0.00566021], dtype=float32),\n",
       " 2415: array([ 0.04526503], dtype=float32),\n",
       " 2416: array([ 0.20880584], dtype=float32),\n",
       " 2518: array([ 0.06314571], dtype=float32),\n",
       " 2525: array([ 0.14890105], dtype=float32),\n",
       " 2553: array([ 0.07872875], dtype=float32),\n",
       " 2602: array([ 0.05135199], dtype=float32),\n",
       " 2630: array([ 0.09139244], dtype=float32),\n",
       " 2648: array([ 0.14420287], dtype=float32),\n",
       " 2773: array([ 0.03276955], dtype=float32),\n",
       " 2801: array([ 0.00920185], dtype=float32),\n",
       " 2902: array([ 0.02187428], dtype=float32),\n",
       " 2973: array([ 0.01832972], dtype=float32),\n",
       " 2976: array([ 0.04917206], dtype=float32),\n",
       " 2997: array([ 0.01949662], dtype=float32),\n",
       " 3029: array([ 0.04539097], dtype=float32),\n",
       " 3056: array([ 0.02946512], dtype=float32),\n",
       " 3120: array([ 0.07801647], dtype=float32),\n",
       " 3133: array([ 0.02660327], dtype=float32),\n",
       " 3154: array([ 0.00443046], dtype=float32),\n",
       " 3190: array([ 0.03832319], dtype=float32),\n",
       " 3282: array([ 0.01043071], dtype=float32),\n",
       " 3287: array([ 0.02709767], dtype=float32),\n",
       " 3301: array([ 0.01114703], dtype=float32),\n",
       " 3341: array([ 0.01603557], dtype=float32),\n",
       " 3368: array([ 0.00825343], dtype=float32),\n",
       " 3452: array([ 0.01078741], dtype=float32),\n",
       " 3475: array([ 0.00572234], dtype=float32),\n",
       " 3511: array([ 0.01103495], dtype=float32),\n",
       " 3525: array([ 0.00624058], dtype=float32),\n",
       " 3537: array([ 0.00461769], dtype=float32),\n",
       " 3540: array([ 0.00925452], dtype=float32),\n",
       " 3561: array([ 0.00625107], dtype=float32),\n",
       " 3644: array([ 0.0044807], dtype=float32),\n",
       " 3658: array([ 0.00499471], dtype=float32)}"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map_item_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  ...],\n",
       " [0,\n",
       "  0.43067655807339306,\n",
       "  0.3154648767857287,\n",
       "  0,\n",
       "  0,\n",
       "  0.3868528072345416,\n",
       "  0.3562071871080222,\n",
       "  0.3154648767857287,\n",
       "  1.0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0.43067655807339306,\n",
       "  0.3154648767857287,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0,\n",
       "  0.5,\n",
       "  0.33333333333333337,\n",
       "  0,\n",
       "  0.5,\n",
       "  0,\n",
       "  0.5,\n",
       "  0,\n",
       "  0.6309297535714574,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0.3562071871080222,\n",
       "  0,\n",
       "  0.3154648767857287,\n",
       "  0.3562071871080222,\n",
       "  1.0,\n",
       "  0.43067655807339306,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1.0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1.0,\n",
       "  0,\n",
       "  0,\n",
       "  1.0,\n",
       "  0.5,\n",
       "  0.6309297535714574,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1.0,\n",
       "  0.30102999566398114,\n",
       "  0,\n",
       "  0.5,\n",
       "  0,\n",
       "  0.43067655807339306,\n",
       "  0,\n",
       "  0.3868528072345416,\n",
       "  0.6309297535714574,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0,\n",
       "  0,\n",
       "  0.3868528072345416,\n",
       "  0,\n",
       "  0.3868528072345416,\n",
       "  1.0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1.0,\n",
       "  0,\n",
       "  0.30102999566398114,\n",
       "  0,\n",
       "  0.5,\n",
       "  0.3868528072345416,\n",
       "  0,\n",
       "  1.0,\n",
       "  0.3154648767857287,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0.3868528072345416,\n",
       "  0,\n",
       "  0.43067655807339306,\n",
       "  0,\n",
       "  0.2890648263178878,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0.30102999566398114,\n",
       "  0,\n",
       "  0,\n",
       "  0.5,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0,\n",
       "  0,\n",
       "  0.3868528072345416,\n",
       "  0,\n",
       "  0.30102999566398114,\n",
       "  0.5,\n",
       "  0,\n",
       "  0.30102999566398114,\n",
       "  0.33333333333333337,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0.5,\n",
       "  0,\n",
       "  0.6309297535714574,\n",
       "  0,\n",
       "  0,\n",
       "  1.0,\n",
       "  0,\n",
       "  0.43067655807339306,\n",
       "  0.3562071871080222,\n",
       "  0.3154648767857287,\n",
       "  0,\n",
       "  0,\n",
       "  0.3868528072345416,\n",
       "  0,\n",
       "  0.6309297535714574,\n",
       "  0,\n",
       "  0.2890648263178878,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1.0,\n",
       "  0.33333333333333337,\n",
       "  0.6309297535714574,\n",
       "  0.5,\n",
       "  0,\n",
       "  0.33333333333333337,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0.33333333333333337,\n",
       "  0.2890648263178878,\n",
       "  0,\n",
       "  0.30102999566398114,\n",
       "  0,\n",
       "  0.6309297535714574,\n",
       "  0.33333333333333337,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1.0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0.33333333333333337,\n",
       "  0.43067655807339306,\n",
       "  0.43067655807339306,\n",
       "  0,\n",
       "  0,\n",
       "  0.3868528072345416,\n",
       "  0,\n",
       "  1.0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0.3154648767857287,\n",
       "  0.6309297535714574,\n",
       "  0,\n",
       "  1.0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0.43067655807339306,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0,\n",
       "  0,\n",
       "  0.33333333333333337,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1.0,\n",
       "  0,\n",
       "  0.3562071871080222,\n",
       "  0,\n",
       "  0.30102999566398114,\n",
       "  0,\n",
       "  0.43067655807339306,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1.0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0.30102999566398114,\n",
       "  1.0,\n",
       "  0.5,\n",
       "  0,\n",
       "  0,\n",
       "  0.6309297535714574,\n",
       "  0.5,\n",
       "  1.0,\n",
       "  0.5,\n",
       "  1.0,\n",
       "  0,\n",
       "  0.5,\n",
       "  0.6309297535714574,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0.3154648767857287,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0.33333333333333337,\n",
       "  1.0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1.0,\n",
       "  0.33333333333333337,\n",
       "  0.6309297535714574,\n",
       "  1.0,\n",
       "  0.33333333333333337,\n",
       "  0,\n",
       "  0,\n",
       "  0.33333333333333337,\n",
       "  0.3868528072345416,\n",
       "  0.5,\n",
       "  0,\n",
       "  1.0,\n",
       "  0.3562071871080222,\n",
       "  0,\n",
       "  1.0,\n",
       "  0,\n",
       "  0,\n",
       "  0.30102999566398114,\n",
       "  0.6309297535714574,\n",
       "  0,\n",
       "  1.0,\n",
       "  0.6309297535714574,\n",
       "  0.43067655807339306,\n",
       "  0,\n",
       "  1.0,\n",
       "  0.43067655807339306,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1.0,\n",
       "  0.5,\n",
       "  0,\n",
       "  0.3154648767857287,\n",
       "  0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0,\n",
       "  0.3154648767857287,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1.0,\n",
       "  0.2890648263178878,\n",
       "  0,\n",
       "  0.6309297535714574,\n",
       "  0,\n",
       "  0.5,\n",
       "  0,\n",
       "  1.0,\n",
       "  0,\n",
       "  0,\n",
       "  0.30102999566398114,\n",
       "  1.0,\n",
       "  0,\n",
       "  0.3154648767857287,\n",
       "  0,\n",
       "  0.6309297535714574,\n",
       "  0.43067655807339306,\n",
       "  0.5,\n",
       "  0.3562071871080222,\n",
       "  0.5,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0.5,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0.5,\n",
       "  0,\n",
       "  0,\n",
       "  0.6309297535714574,\n",
       "  0.3562071871080222,\n",
       "  0,\n",
       "  0.3154648767857287,\n",
       "  0.30102999566398114,\n",
       "  0,\n",
       "  0,\n",
       "  0.6309297535714574,\n",
       "  0.5,\n",
       "  0.3154648767857287,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1.0,\n",
       "  0,\n",
       "  0,\n",
       "  0.6309297535714574,\n",
       "  1.0,\n",
       "  0,\n",
       "  0,\n",
       "  0.43067655807339306,\n",
       "  0.5,\n",
       "  0.5,\n",
       "  1.0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0.33333333333333337,\n",
       "  1.0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0.3562071871080222,\n",
       "  0,\n",
       "  0.3154648767857287,\n",
       "  0.43067655807339306,\n",
       "  1.0,\n",
       "  0.30102999566398114,\n",
       "  0,\n",
       "  0,\n",
       "  0.5,\n",
       "  1.0,\n",
       "  0,\n",
       "  0.3562071871080222,\n",
       "  0.5,\n",
       "  0,\n",
       "  1.0,\n",
       "  0.5,\n",
       "  0,\n",
       "  1.0,\n",
       "  0.5,\n",
       "  0.6309297535714574,\n",
       "  0.5,\n",
       "  0,\n",
       "  1.0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0.6309297535714574,\n",
       "  0,\n",
       "  0.2890648263178878,\n",
       "  0,\n",
       "  0.6309297535714574,\n",
       "  1.0,\n",
       "  0.5,\n",
       "  0,\n",
       "  0.6309297535714574,\n",
       "  0,\n",
       "  0,\n",
       "  0.3868528072345416,\n",
       "  0.5,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0.6309297535714574,\n",
       "  0,\n",
       "  0.33333333333333337,\n",
       "  0.5,\n",
       "  1.0,\n",
       "  0.6309297535714574,\n",
       "  0.3868528072345416,\n",
       "  0,\n",
       "  0.43067655807339306,\n",
       "  0.5,\n",
       "  0.5,\n",
       "  0.5,\n",
       "  0,\n",
       "  0,\n",
       "  0.43067655807339306,\n",
       "  0,\n",
       "  0,\n",
       "  1.0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0.3868528072345416,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0.3154648767857287,\n",
       "  1.0,\n",
       "  0.5,\n",
       "  0.5,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0.30102999566398114,\n",
       "  0.5,\n",
       "  0.3868528072345416,\n",
       "  0.3868528072345416,\n",
       "  0.5,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0.6309297535714574,\n",
       "  0,\n",
       "  0,\n",
       "  0.3562071871080222,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0.6309297535714574,\n",
       "  0.43067655807339306,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0.43067655807339306,\n",
       "  1.0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0.5,\n",
       "  0.3868528072345416,\n",
       "  0,\n",
       "  0.30102999566398114,\n",
       "  0,\n",
       "  0.6309297535714574,\n",
       "  1.0,\n",
       "  0.3154648767857287,\n",
       "  0,\n",
       "  0.2890648263178878,\n",
       "  0,\n",
       "  1.0,\n",
       "  0,\n",
       "  0.3562071871080222,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0.5,\n",
       "  0,\n",
       "  1.0,\n",
       "  0.3868528072345416,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0.6309297535714574,\n",
       "  0.33333333333333337,\n",
       "  0,\n",
       "  0.43067655807339306,\n",
       "  0.6309297535714574,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0.6309297535714574,\n",
       "  0,\n",
       "  0.5,\n",
       "  0,\n",
       "  0.30102999566398114,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0.33333333333333337,\n",
       "  0,\n",
       "  1.0,\n",
       "  0.30102999566398114,\n",
       "  0,\n",
       "  0,\n",
       "  0.43067655807339306,\n",
       "  0.3868528072345416,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0.5,\n",
       "  0,\n",
       "  0.6309297535714574,\n",
       "  0,\n",
       "  0.3868528072345416,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1.0,\n",
       "  0.6309297535714574,\n",
       "  0.30102999566398114,\n",
       "  1.0,\n",
       "  0.3868528072345416,\n",
       "  0.6309297535714574,\n",
       "  1.0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1.0,\n",
       "  0.3868528072345416,\n",
       "  0.2890648263178878,\n",
       "  0,\n",
       "  0.3868528072345416,\n",
       "  0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0.3868528072345416,\n",
       "  0.43067655807339306,\n",
       "  0,\n",
       "  0.30102999566398114,\n",
       "  0,\n",
       "  0,\n",
       "  0.6309297535714574,\n",
       "  0.3154648767857287,\n",
       "  1.0,\n",
       "  0.30102999566398114,\n",
       "  0,\n",
       "  0.6309297535714574,\n",
       "  0.33333333333333337,\n",
       "  0,\n",
       "  0.3154648767857287,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0.6309297535714574,\n",
       "  0.3562071871080222,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1.0,\n",
       "  0.43067655807339306,\n",
       "  0.3868528072345416,\n",
       "  0,\n",
       "  0,\n",
       "  0.6309297535714574,\n",
       "  1.0,\n",
       "  0.3868528072345416,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1.0,\n",
       "  0,\n",
       "  0.6309297535714574,\n",
       "  0.5,\n",
       "  0.43067655807339306,\n",
       "  0.2890648263178878,\n",
       "  1.0,\n",
       "  0,\n",
       "  0,\n",
       "  1.0,\n",
       "  0.2890648263178878,\n",
       "  0,\n",
       "  1.0,\n",
       "  0.6309297535714574,\n",
       "  0.6309297535714574,\n",
       "  0,\n",
       "  0.5,\n",
       "  0,\n",
       "  0,\n",
       "  0.3868528072345416,\n",
       "  0,\n",
       "  0,\n",
       "  0.5,\n",
       "  0,\n",
       "  0.33333333333333337,\n",
       "  0.43067655807339306,\n",
       "  0,\n",
       "  0.43067655807339306,\n",
       "  0.3868528072345416,\n",
       "  0,\n",
       "  0,\n",
       "  0.6309297535714574,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0.30102999566398114,\n",
       "  0,\n",
       "  1.0,\n",
       "  0.3154648767857287,\n",
       "  1.0,\n",
       "  0.6309297535714574,\n",
       "  0,\n",
       "  0.33333333333333337,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0.33333333333333337,\n",
       "  0,\n",
       "  1.0,\n",
       "  0,\n",
       "  0.5,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0.3868528072345416,\n",
       "  0.6309297535714574,\n",
       "  0.3868528072345416,\n",
       "  0,\n",
       "  1.0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0.43067655807339306,\n",
       "  0.33333333333333337,\n",
       "  0,\n",
       "  0.30102999566398114,\n",
       "  0.5,\n",
       "  0,\n",
       "  0,\n",
       "  0.3868528072345416,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0.6309297535714574,\n",
       "  0,\n",
       "  1.0,\n",
       "  0.5,\n",
       "  1.0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0.33333333333333337,\n",
       "  0.33333333333333337,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0.3562071871080222,\n",
       "  0,\n",
       "  0,\n",
       "  0.5,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0.5,\n",
       "  0.43067655807339306,\n",
       "  0,\n",
       "  0.5,\n",
       "  1.0,\n",
       "  0.6309297535714574,\n",
       "  0.30102999566398114,\n",
       "  0,\n",
       "  1.0,\n",
       "  0,\n",
       "  0.5,\n",
       "  0.3562071871080222,\n",
       "  0.5,\n",
       "  1.0,\n",
       "  0.6309297535714574,\n",
       "  0.6309297535714574,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0.33333333333333337,\n",
       "  0.30102999566398114,\n",
       "  1.0,\n",
       "  0.2890648263178878,\n",
       "  0,\n",
       "  1.0,\n",
       "  0.2890648263178878,\n",
       "  0,\n",
       "  1.0,\n",
       "  0.3562071871080222,\n",
       "  1.0,\n",
       "  0,\n",
       "  0,\n",
       "  1.0,\n",
       "  0,\n",
       "  0,\n",
       "  0.3562071871080222,\n",
       "  0.5,\n",
       "  1.0,\n",
       "  0.33333333333333337,\n",
       "  1.0,\n",
       "  0.5,\n",
       "  1.0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0.6309297535714574,\n",
       "  1.0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0.6309297535714574,\n",
       "  0,\n",
       "  1.0,\n",
       "  0.2890648263178878,\n",
       "  1.0,\n",
       "  0,\n",
       "  1.0,\n",
       "  0.6309297535714574,\n",
       "  0,\n",
       "  0.5,\n",
       "  0.5,\n",
       "  1.0,\n",
       "  0,\n",
       "  0,\n",
       "  0.6309297535714574,\n",
       "  0,\n",
       "  0,\n",
       "  0.5,\n",
       "  0,\n",
       "  0.3154648767857287,\n",
       "  1.0,\n",
       "  0.33333333333333337,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.6309297535714574,\n",
       "  0,\n",
       "  1.0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0.3154648767857287,\n",
       "  0,\n",
       "  0,\n",
       "  0.43067655807339306,\n",
       "  0,\n",
       "  0,\n",
       "  0.43067655807339306,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1.0,\n",
       "  0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.3154648767857287,\n",
       "  0.2890648263178878,\n",
       "  0,\n",
       "  0.3562071871080222,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0.5,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0.43067655807339306,\n",
       "  0.6309297535714574,\n",
       "  0,\n",
       "  0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0.6309297535714574,\n",
       "  0,\n",
       "  0.33333333333333337,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0.43067655807339306,\n",
       "  0.6309297535714574,\n",
       "  1.0,\n",
       "  0.6309297535714574,\n",
       "  0,\n",
       "  0.43067655807339306,\n",
       "  0,\n",
       "  0.6309297535714574,\n",
       "  0.5,\n",
       "  0.5,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0.3562071871080222,\n",
       "  0.33333333333333337,\n",
       "  0.2890648263178878,\n",
       "  0,\n",
       "  0.6309297535714574,\n",
       "  0,\n",
       "  0.43067655807339306,\n",
       "  0.33333333333333337,\n",
       "  0.43067655807339306,\n",
       "  1.0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0.33333333333333337,\n",
       "  0,\n",
       "  0.3868528072345416,\n",
       "  0,\n",
       "  0.3868528072345416,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0.3868528072345416,\n",
       "  0.6309297535714574,\n",
       "  0.6309297535714574,\n",
       "  0,\n",
       "  0,\n",
       "  1.0,\n",
       "  0.5,\n",
       "  0,\n",
       "  1.0,\n",
       "  0.3562071871080222,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1.0,\n",
       "  0,\n",
       "  1.0,\n",
       "  0.2890648263178878,\n",
       "  0,\n",
       "  0.5,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1.0,\n",
       "  0,\n",
       "  0.6309297535714574,\n",
       "  0,\n",
       "  0,\n",
       "  0.6309297535714574,\n",
       "  0.3868528072345416,\n",
       "  0.6309297535714574,\n",
       "  0.2890648263178878,\n",
       "  0,\n",
       "  0,\n",
       "  0.33333333333333337,\n",
       "  0.5,\n",
       "  0.2890648263178878,\n",
       "  0.3868528072345416,\n",
       "  0,\n",
       "  1.0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0.43067655807339306,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0.3562071871080222,\n",
       "  0.43067655807339306,\n",
       "  0.33333333333333337,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1.0,\n",
       "  0.5,\n",
       "  0,\n",
       "  0.3868528072345416,\n",
       "  0.3868528072345416,\n",
       "  0,\n",
       "  0,\n",
       "  0.33333333333333337,\n",
       "  1.0,\n",
       "  0,\n",
       "  0.2890648263178878,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0.3154648767857287,\n",
       "  0.6309297535714574,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0.3868528072345416,\n",
       "  0.3562071871080222,\n",
       "  0,\n",
       "  0.43067655807339306,\n",
       "  0,\n",
       "  0.33333333333333337,\n",
       "  0,\n",
       "  0.3868528072345416,\n",
       "  0,\n",
       "  0.6309297535714574,\n",
       "  0,\n",
       "  0,\n",
       "  0.3868528072345416,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0.43067655807339306,\n",
       "  0.5,\n",
       "  0,\n",
       "  0,\n",
       "  0.3154648767857287,\n",
       "  0,\n",
       "  0,\n",
       "  0.6309297535714574,\n",
       "  0,\n",
       "  0,\n",
       "  0.5,\n",
       "  0,\n",
       "  0.43067655807339306,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0.5,\n",
       "  0.6309297535714574,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  ...])"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_model(model,testRatings=testRatings,testNegatives=testNegatives, K=10, num_thread=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
